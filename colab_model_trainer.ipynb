{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "package-installation"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch box ensure pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import yaml\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "import torch\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utils"
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            content = yaml.safe_load(yaml_file)\n",
    "            return ConfigBox(content)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Configuration and parameters\n",
    "config = read_yaml('config.yaml')\n",
    "params = read_yaml('params.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model-trainer"
   },
   "outputs": [],
   "source": [
    "# Model Trainer Class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def train(self):\n",
    "        # Verify GPU availability\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f'Using device: {device}')\n",
    "\n",
    "        # Initialize model and tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt).to(device)\n",
    "\n",
    "        # Load dataset\n",
    "        dataset = load_from_disk(self.config.data_path)\n",
    "\n",
    "        # Training setup\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=self.config.root_dir,\n",
    "            num_train_epochs=params.TrainingArguments.num_train_epochs,\n",
    "            per_device_train_batch_size=params.TrainingArguments.per_device_train_batch_size,\n",
    "            evaluation_strategy=params.TrainingArguments.evaluation_strategy,\n",
    "            eval_steps=params.TrainingArguments.eval_steps,\n",
    "            save_steps=params.TrainingArguments.save_steps,\n",
    "            gradient_accumulation_steps=params.TrainingArguments.gradient_accumulation_steps\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_args,\n",
    "            tokenizer=tokenizer,\n",
    "            train_dataset=dataset['test'],\n",
    "            eval_dataset=dataset['validation']\n",
    "        )\n",
    "\n",
    "        # Start training\n",
    "        trainer.train()\n",
    "\n",
    "        # Save model and tokenizer\n",
    "        model.save_pretrained(os.path.join(self.config.root_dir, 'pegasus-samsum-model'))\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir, 'tokenizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "execution"
   },
   "outputs": [],
   "source": [
    "# Execute training\n",
    "trainer = ModelTrainer(config.model_trainer)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
